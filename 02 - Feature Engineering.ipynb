{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a40ac6d2",
   "metadata": {},
   "source": [
    "# Netflix movie recommendation engine\n",
    "Kaggle competition link: https://www.kaggle.com/datasets/netflix-inc/netflix-prize-data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c5c4d8",
   "metadata": {},
   "source": [
    "After doing some preprocessing, now we have 2 datasets in sparse matrix format. \n",
    "1. train_sparse_matrix\n",
    "2. test_sparse_matrix\n",
    "\n",
    "Both the data sets have 'user' as rows and 'movie' as columns and 'rating' as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41f48c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from datetime import datetime # To compute time taken wherever necessary\n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b552454e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_sparse_matrix loaded!\n",
      "test_sparse_matrix loaded!\n"
     ]
    }
   ],
   "source": [
    "# Load train & test sparse matrix which we've created in previous file\n",
    "transformed_folder = 'F:/09 - Machine Learning Case Studies/01 - Netflix Movies Recommendation/Transformed Data'\n",
    "train_sparse_matrix = sparse.load_npz(transformed_folder+'/train_sparse_matrix.npz')\n",
    "print('train_sparse_matrix loaded!')\n",
    "test_sparse_matrix = sparse.load_npz(transformed_folder+'/test_sparse_matrix.npz')\n",
    "print('test_sparse_matrix loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94dddce",
   "metadata": {},
   "source": [
    "### 1. Create samples and do feature enginnering on sample data sets\n",
    "The train dataset contains 405k users & 17k movies while test dataset contains 35k users & 17k movies. If we perform similarity computation & featurization on these, it will take a lot of time considering my local machine. To save time, lets create a sample of these datasets and operate on them. Later we can extend the same operations on full dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1afb045",
   "metadata": {},
   "source": [
    "#### A function that takes sparse matrix and returns sample sparse matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c55c41c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(sparse_matrix, no_users, no_movies, file_name):\n",
    "    \n",
    "    row_index, col_index, ratings = sparse.find(sparse_matrix)\n",
    "    users = np.unique(row_index)\n",
    "    movies = np.unique (col_index)\n",
    "    \n",
    "    print(\"Original matrix stats\")\n",
    "    print(\"Users: {}\\nMovies: {}\\nRatings: {}\".format(len(users), len(movies), len(ratings)))\n",
    "    \n",
    "    # Pick random state so we will get same samples everytime \n",
    "    np.random.seed(15)\n",
    "    # Pick samples without replacement\n",
    "    sample_users = np.random.choice(users, no_users, replace=False)\n",
    "    sample_movies = np.random.choice(movies, no_movies, replace=False)\n",
    "    \n",
    "    # Get the boolean mask of these sampled indexes from original matrix. \n",
    "    # This will help us to directly use index reference to pick the rating \n",
    "    boolean_mask = np.logical_and(np.isin(row_index, sample_users), np.isin(col_index, sample_movies))\n",
    "    \n",
    "    # Pick the sample values which from the index where boolean_mask is returning true\n",
    "    sample_sparse_matrix = sparse.csc_matrix( (ratings[boolean_mask], (row_index[boolean_mask], col_index[boolean_mask])),\n",
    "                                            shape = (max(sample_users)+1, max(sample_movies)+1) )\n",
    "\n",
    "    print(\"\\nSampled matrix stats\")\n",
    "    print(\"Users: {}\\nMovies: {}\\nRatings: {}\".format(len(sample_users), len(sample_movies), ratings[boolean_mask].shape[0]))\n",
    "    \n",
    "    print('Saving to {}'.format(transformed_folder+'/'+file_name))\n",
    "    sparse.save_npz(transformed_folder+'/'+file_name, sample_sparse_matrix)\n",
    "    return sample_sparse_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c8fb0a",
   "metadata": {},
   "source": [
    "#### 1.1 Create sample_train_sparse_matrix from train_sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "2c0562ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating sample_train_sparse_matrix from train_sparse_matrix...\n",
      "Original matrix stats\n",
      "Users: 405041\n",
      "Movies: 17424\n",
      "Ratings: 80384405\n",
      "\n",
      "Sampled matrix stats\n",
      "Users: 25000\n",
      "Movies: 3000\n",
      "Ratings: 856986\n",
      "Saving to F:/09 - Machine Learning Case Studies/01 - Netflix Movies Recommendation/Transformed Data/sample_train_sparse_matrix.npz\n",
      "Done!\n",
      "Time taken: 0:00:31.997092\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "if os.path.isfile(transformed_folder+'/sample_train_sparse_matrix.npz'):\n",
    "    print('Sparse matrix for sample train already exists. Getting it from disk...')\n",
    "    sample_train_sparse_matrix = sparse.load_npz(transformed_folder+'/sample_train_sparse_matrix.npz')\n",
    "    print('Done!')\n",
    "    print('Time taken: {}'.format(datetime.now() - start))\n",
    "else:\n",
    "    print('Creating sample_train_sparse_matrix from train_sparse_matrix...')\n",
    "    sample_train_sparse_matrix = get_sample(sparse_matrix=train_sparse_matrix, no_users=25000, \n",
    "                                            no_movies=3000, file_name=\"sample_train_sparse_matrix.npz\")\n",
    "    print('Done!')\n",
    "    print('Time taken: {}'.format(datetime.now() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0971af93",
   "metadata": {},
   "source": [
    "#### 1.2 Create sample_test_sparse_matrix from test_sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "3b5af4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating sample_train_sparse_matrix from test_sparse_matrix...\n",
      "Original matrix stats\n",
      "Users: 349312\n",
      "Movies: 17757\n",
      "Ratings: 20096102\n",
      "\n",
      "Sampled matrix stats\n",
      "Users: 15000\n",
      "Movies: 2000\n",
      "Ratings: 103997\n",
      "Saving to F:/09 - Machine Learning Case Studies/01 - Netflix Movies Recommendation/Transformed Data/sample_test_sparse_matrix.npz\n",
      "Done!\n",
      "Time taken: 0:00:06.803585\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "if os.path.isfile(transformed_folder+'/sample_test_sparse_matrix.npz'):\n",
    "    print('Sparse matrix for sample test already exists. Getting it from disk...')\n",
    "    sample_test_sparse_matrix = sparse.load_npz(transformed_folder+'/sample_test_sparse_matrix.npz')\n",
    "    print('Done!')\n",
    "    print('Time taken: {}'.format(datetime.now() - start))\n",
    "else:\n",
    "    print('Creating sample_train_sparse_matrix from test_sparse_matrix...')\n",
    "    sample_test_sparse_matrix = get_sample(sparse_matrix=test_sparse_matrix, no_users=15000, \n",
    "                                            no_movies=2000, file_name=\"sample_test_sparse_matrix.npz\")\n",
    "    print('Done!')\n",
    "    print('Time taken: {}'.format(datetime.now() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "e058ef97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings in train_sparse_matrix: 80384405\n",
      "Ratings in sample_train_sparse_matrix: 856986\n",
      "\n",
      "Ratings in test_sparse_matrix: 20096102\n",
      "Ratings in sample_test_sparse_matrix: 103997\n"
     ]
    }
   ],
   "source": [
    "# Compare samples with original\n",
    "print('Ratings in train_sparse_matrix: {}'.format(train_sparse_matrix.count_nonzero()))\n",
    "print('Ratings in sample_train_sparse_matrix: {}'.format(sample_train_sparse_matrix.count_nonzero()))\n",
    "\n",
    "print('\\nRatings in test_sparse_matrix: {}'.format(test_sparse_matrix.count_nonzero()))\n",
    "print('Ratings in sample_test_sparse_matrix: {}'.format(sample_test_sparse_matrix.count_nonzero()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "99fbb16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change variable names for ease\n",
    "del train_sparse_matrix\n",
    "del test_sparse_matrix\n",
    "train_sparse_matrix = sample_train_sparse_matrix\n",
    "test_sparse_matrix = sample_test_sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "8d6e2e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings in train_sparse_matrix: 856986\n",
      "Ratings in sample_train_sparse_matrix: 856986\n",
      "\n",
      "Ratings in test_sparse_matrix: 103997\n",
      "Ratings in sample_test_sparse_matrix: 103997\n"
     ]
    }
   ],
   "source": [
    "# After changing variable names\n",
    "print('Ratings in train_sparse_matrix: {}'.format(train_sparse_matrix.count_nonzero()))\n",
    "print('Ratings in sample_train_sparse_matrix: {}'.format(sample_train_sparse_matrix.count_nonzero()))\n",
    "\n",
    "print('\\nRatings in test_sparse_matrix: {}'.format(test_sparse_matrix.count_nonzero()))\n",
    "print('Ratings in sample_test_sparse_matrix: {}'.format(sample_test_sparse_matrix.count_nonzero()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9857f49f",
   "metadata": {},
   "source": [
    "### 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aed592d",
   "metadata": {},
   "source": [
    "#### 2.1 Basic features based on statistics\n",
    "Lets try to build some features that will be useful in modelling. Few such features could be:\n",
    "1. Average of all ratings given\n",
    "2. Average rating per user\n",
    "3. Average rating per movie\n",
    "\n",
    "We will create a dictionary train_averages which will store all these values. Like:<br>\n",
    "train_averages = <br>\n",
    "{<br>\n",
    "'global_average' : xyz,<br>\n",
    "'user' : { 'user1': abc, 'user2':pqr},<br>\n",
    "'movie' : { 'movie1': abc, 'movie2':pqr}<br>\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "406c5151",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_averages = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615241cf",
   "metadata": {},
   "source": [
    "#### Global average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "65d8191b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'global_average': 3.5875813607223455}\n",
      "**************************************************\n",
      "Time taken: 0:00:00.021661\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "# Global average\n",
    "train_averages['global_average'] = train_sparse_matrix.sum()/train_sparse_matrix.count_nonzero()\n",
    "print(train_averages)\n",
    "print(\"*\"*50)\n",
    "print('Time taken: {}'.format(datetime.now() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5befab76",
   "metadata": {},
   "source": [
    "#### Average rating per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "1ad8c613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing average ratings per user...\n",
      "Done!\n",
      "**************************************************\n",
      "Time taken: 0:00:00.514203\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "# Average rating per user\n",
    "print('Computing average ratings per user...')\n",
    "sum_of_ratings_per_user = train_sparse_matrix.sum(axis=1).A1\n",
    "no_of_ratings_per_user = (train_sparse_matrix!=0).sum(axis=1).A1\n",
    "\n",
    "u,m = train_sparse_matrix.shape\n",
    "average_ratings = dict()\n",
    "for i in range(0,u):\n",
    "    if no_of_ratings_per_user[i]!=0:\n",
    "        average_ratings[i] = sum_of_ratings_per_user[i]/no_of_ratings_per_user[i]\n",
    "\n",
    "train_averages['user'] = average_ratings\n",
    "print('Done!')\n",
    "print(\"*\"*50)\n",
    "print('Time taken: {}'.format(datetime.now() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "41205b58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average rating given by user 14531 is: 3.7142857142857144\n"
     ]
    }
   ],
   "source": [
    "print('Average rating given by user 14531 is: {}'.format(train_averages['user'][14531]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b916df7",
   "metadata": {},
   "source": [
    "#### Average rating per movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "3ef4a3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing average ratings per movie...\n",
      "Done!\n",
      "**************************************************\n",
      "Time taken: 0:00:00.016515\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "# Average rating per user\n",
    "print('Computing average ratings per movie...')\n",
    "sum_of_ratings_per_movie = train_sparse_matrix.sum(axis=0).A1\n",
    "no_of_ratings_per_movie = (train_sparse_matrix!=0).sum(axis=0).A1\n",
    "\n",
    "u,m = train_sparse_matrix.shape\n",
    "average_ratings = dict()\n",
    "for i in range(0,m):\n",
    "    if no_of_ratings_per_movie[i]!=0:\n",
    "        average_ratings[i] = sum_of_ratings_per_movie[i]/no_of_ratings_per_movie[i]\n",
    "\n",
    "train_averages['movie'] = average_ratings\n",
    "print('Done!')\n",
    "print(\"*\"*50)\n",
    "print('Time taken: {}'.format(datetime.now() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "22ee58a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average rating given for movie 40 is: 2.6923076923076925\n"
     ]
    }
   ],
   "source": [
    "print('Average rating given for movie 40 is: {}'.format(train_averages['movie'][40]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c7697d",
   "metadata": {},
   "source": [
    "#### 2.2 Compute user-user similarity matrix\n",
    "\n",
    "We know that there are more than 400k users. If we try to compute similarity using cosine similarity, we will need to do (400k * 400k / 2) = 80 billions computations, which will take days to compute even though it will only perform on nonzeros. <br>\n",
    "If we try to reduce number of dimensions using PCA or SVD, it will take even more time as the matrix will become dense and the multiplication will be done for each feature as there will not be zero cells. <br><br>\n",
    "\n",
    "One of the ideas is to compute similarity at <b>run time</b>. Here, we will follow below startegy to compute user-user similarity:<br>\n",
    "1. We will compute similarity (top N) for given user (run time)\n",
    "2. Once we compute similarity for any user, we will store this data in our customized data structure so that we can retirve it whenever we want in future\n",
    "3. Now next time if we want to compute similarity for any user, first we will check if we have already computed for that particular user. If yes, then get it from out customized data structure. If not, compute the similarity and store it in our customized data structure.\n",
    "<br><br>\n",
    "Our customized data structure will be a <b>dictionary of dictionaries</b><br>\n",
    "{ 'user1': {'similar_user1' : value1 }, {'similar_user2' : value2 }, {'similar_user3' : value3 } <br>\n",
    "  'user2': {'similar_user1' : value1 }, {'similar_user2' : value2 }, {'similar_user3' : value3 } }\n",
    "  \n",
    "<br>\n",
    "For now, since we have taken sample of users, lets compute similarity using cosine_similarity which wouldn't take much time.<br>\n",
    "<b>From the result of this, we will pick top 5 similar users and take them as features to train our model.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a042bd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "c4d187ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating sparse matrix for user-user similarity...\n",
      "Saving to F:/09 - Machine Learning Case Studies/01 - Netflix Movies Recommendation/Transformed Data/u_u_similarity_sparse.npz\n",
      "Done!\n",
      "Time taken: 0:04:06.605539\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "# To compute this, we will use consine similarity\n",
    "if os.path.isfile(transformed_folder+'/u_u_similarity_sparse.npz'):\n",
    "    print('Sparse matrix for user-user similarity already exists, getting it from disk... ')\n",
    "    u_u_similarity_sparse = sparse.load_npz(transformed_folder+'/u_u_similarity_sparse.npz')\n",
    "    print('Done!')\n",
    "    print('Time taken; {}'.format(datetime.now() - start))\n",
    "else:\n",
    "    print('Creating sparse matrix for user-user similarity...')\n",
    "    u_u_similarity_sparse = cosine_similarity(X=train_sparse_matrix, dense_output=Falseb)\n",
    "    print('Saving to {}'.format(transformed_folder+'/u_u_similarity_sparse.npz'))\n",
    "    sparse.save_npz(transformed_folder+'/u_u_similarity_sparse.npz', u_u_similarity_sparse)\n",
    "    print('Done!')\n",
    "    print('Time taken: {}'.format(datetime.now() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "4162b891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of user-user similarity matrix: (2649405, 2649405)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of user-user similarity matrix: {}'.format(u_u_similarity_sparse.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57b1605",
   "metadata": {},
   "source": [
    "We have computed similarity between each user that we have. In reality, we only care about top 10 or 20 users that we can check their movies for the user. For this, we will maintain a separate dictionary and refer to it when we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "5a529862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique user IDs\n",
    "user_ids = np.unique(u_u_similarity_sparse.nonzero()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "cb2cb9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique users: 24029\n"
     ]
    }
   ],
   "source": [
    "print('Total number of unique users: {}'.format(len(user_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "6389ad33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dictionary of top 20 users for each user\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 20.2 MiB for an array with shape (2649405,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [183], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCreating dictionary of top 20 users for each user\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m user \u001b[38;5;129;01min\u001b[39;00m user_ids:\n\u001b[1;32m----> 6\u001b[0m     sim_users \u001b[38;5;241m=\u001b[39m \u001b[43mu_u_similarity_sparse\u001b[49m\u001b[43m[\u001b[49m\u001b[43muser\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margsort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# toarray() : converts sparse matrix to dense matrix\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# ravel() : flattens the 1-D array\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# argsort() : returns the indexes of values in ascending sorted order\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# [::-1] : sorts the array in descending order\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# [1:] : Skips the first user since its the same user itself\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     similar_users[user] \u001b[38;5;241m=\u001b[39m sim_users[:\u001b[38;5;241m20\u001b[39m]\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 20.2 MiB for an array with shape (2649405,) and data type int64"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "# Create dictionary of top 20 similar users for each of the user based on similarity matrix\n",
    "similar_users = dict()\n",
    "print('Creating dictionary of top 20 users for each user...')\n",
    "for user in user_ids:\n",
    "    sim_users = u_u_similarity_sparse[user].toarray().ravel().argsort()[::-1][1:]\n",
    "    # toarray() : converts sparse matrix to dense matrix\n",
    "    # ravel() : flattens the 1-D array\n",
    "    # argsort() : returns the indexes of values in ascending sorted order\n",
    "    # [::-1] : sorts the array in descending order\n",
    "    # [1:] : Skips the first user since its the same user itself\n",
    "    similar_users[user] = sim_users[:20]\n",
    "print('Done!')\n",
    "print('Time taken: {}'.format(datetime.now() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc75eee4",
   "metadata": {},
   "source": [
    "#### 2.3 Compute movie-movie similarity matrix\n",
    "\n",
    "We know that there are around 17k movies in total. If we try to compute cosine similarity, we will need to do (17k * 17k / 2) = 144 millions computations, which would not take much longer. In this case, we can definately go with cosine similarity to get similar movies for each movie.\n",
    "\n",
    "<br>\n",
    "<b>From the result of this, we will pick top 5 similar movies and take them as features to train our model.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "30cd42c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating sparse matrix for movie-movie similarity...\n",
      "Saving to F:/09 - Machine Learning Case Studies/01 - Netflix Movies Recommendation/Transformed Data/m_m_similarity_sparse.npz\n",
      "Done!\n",
      "Time taken: 0:00:00.257410\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "# To compute this, we will use consine similarity\n",
    "if os.path.isfile(transformed_folder+'/m_m_similarity_sparse.npz'):\n",
    "    print('Sparse matrix for movie-movie similarity already exists, getting it from disk... ')\n",
    "    m_m_similarity_sparse = sparse.load_npz(transformed_folder+'/m_m_similarity_sparse.npz')\n",
    "    print('Done!')\n",
    "    print('Time taken; {}'.format(datetime.now() - start))\n",
    "else:\n",
    "    print('Creating sparse matrix for movie-movie similarity...')\n",
    "    m_m_similarity_sparse = cosine_similarity(X=train_sparse_matrix.T, dense_output=False)\n",
    "    print('Saving to {}'.format(transformed_folder+'/m_m_similarity_sparse.npz'))\n",
    "    sparse.save_npz(transformed_folder+'/m_m_similarity_sparse.npz', m_m_similarity_sparse)\n",
    "    print('Done!')\n",
    "    print('Time taken: {}'.format(datetime.now() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4d297655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of movie-movie similarity matrix: (17724, 17724)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of movie-movie similarity matrix: {}'.format(m_m_similarity_sparse.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f21d97",
   "metadata": {},
   "source": [
    "We have computed similarity between each movies that we have. In reality, we only care about top 10 or 20 movies that we can recommend to user. For this, we will maintain a separate dictionary and refer to it when we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "beae34db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique movie IDs which have atleast 1 rating\n",
    "movie_ids = np.unique(m_m_similarity_sparse.nonzero()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "15b1bed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dictionary of top 20 movies for each movie\n",
      "Done!\n",
      "Time taken: 0:00:00.281233\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "# Create dictionary of top 20 movies for each of the movies based on similarity matrix\n",
    "similar_movies = dict()\n",
    "print('Creating dictionary of top 20 movies for each movie')\n",
    "for movie in movie_ids:\n",
    "    sim_movies = m_m_similarity_sparse[movie].toarray().ravel().argsort()[::-1][1:]\n",
    "    # toarray() : converts sparse matrix to dense matrix\n",
    "    # ravel() : flattens the 1-D array\n",
    "    # argsort() : returns the indexes of values in ascending sorted order\n",
    "    # [::-1] : sorts the array in descending order\n",
    "    # [1:] : Skips the first element since its the same movie itself\n",
    "    similar_movies[movie] = sim_movies[:20]\n",
    "print('Done!')\n",
    "print('Time taken: {}'.format(datetime.now() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8d2a80",
   "metadata": {},
   "source": [
    "### 3. Featurizing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726d16f0",
   "metadata": {},
   "source": [
    "As of now, we have below features that we want our model to be trained on:\n",
    "1. Global average\n",
    "2. Average rating by the user\n",
    "3. Average rating for the movie\n",
    "4. Ratings received from top 5 similar users for the movie\n",
    "5. Ratings given for top 5 similar movies from the user\n",
    "\n",
    "In total, we have 13 features to train our base model on. Lets featurize these to bring them in a required format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6d4783d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 2, 0, 2, 1, 2], dtype=int32),\n",
       " array([0, 0, 1, 1, 2, 2], dtype=int32),\n",
       " array([7., 1., 8., 2., 9., 3.]))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix, find\n",
    "A = csr_matrix([[7.0, 8.0, 0],[0, 0, 9.0], [1,2,3]])\n",
    "find(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ed77435d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7., 8., 0.],\n",
       "       [0., 0., 9.],\n",
       "       [1., 2., 3.]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b602f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ds] *",
   "language": "python",
   "name": "conda-env-ds-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
