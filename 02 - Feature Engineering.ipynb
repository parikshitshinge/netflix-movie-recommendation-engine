{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a40ac6d2",
   "metadata": {},
   "source": [
    "# Netflix movie recommendation engine\n",
    "Kaggle competition link: https://www.kaggle.com/datasets/netflix-inc/netflix-prize-data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c5c4d8",
   "metadata": {},
   "source": [
    "After doing some preprocessing, now we have 2 datasets in sparse matrix format. \n",
    "1. train_sparse_matrix\n",
    "2. test_sparse_matrix\n",
    "\n",
    "Both the data sets have 'user' as rows and 'movie' as columns and 'rating' as data.<br>\n",
    "\n",
    "Here, our goal is to create most relevant features to train our model on so that it can be as accurate as possible. We will create below 13 features and make the model ready dataset for train & test:\n",
    "1. Global average\n",
    "2. Average rating by the user\n",
    "3. Average rating for the movie\n",
    "4. Ratings received from top 5 similar users for the movie\n",
    "5. Ratings given for top 5 similar movies from the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41f48c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from datetime import datetime # To compute time taken wherever necessary\n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b552454e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_sparse_matrix loaded!\n",
      "test_sparse_matrix loaded!\n"
     ]
    }
   ],
   "source": [
    "# Load train & test sparse matrix which we've created in previous file\n",
    "transformed_folder = 'F:/09 - Machine Learning Case Studies/01 - Netflix Movies Recommendation/Transformed Data'\n",
    "train_sparse_matrix = sparse.load_npz(transformed_folder+'/train_sparse_matrix.npz')\n",
    "print('train_sparse_matrix loaded!')\n",
    "test_sparse_matrix = sparse.load_npz(transformed_folder+'/test_sparse_matrix.npz')\n",
    "print('test_sparse_matrix loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94dddce",
   "metadata": {},
   "source": [
    "### 1. Create samples and do feature enginnering on sample data sets\n",
    "The train dataset contains 405k users & 17k movies while test dataset contains 35k users & 17k movies. If we perform similarity computation & featurization on these, it will take a lot of time considering my local machine. To save time, lets create a sample of these datasets and operate on them. Later we can extend the same operations on full dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1afb045",
   "metadata": {},
   "source": [
    "#### A function that takes sparse matrix and returns sample sparse matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c55c41c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(sparse_matrix, no_users, no_movies, file_name):\n",
    "    \n",
    "    row_index, col_index, ratings = sparse.find(sparse_matrix)\n",
    "    users = np.unique(row_index)\n",
    "    movies = np.unique (col_index)\n",
    "    \n",
    "    print(\"Original matrix stats\")\n",
    "    print(\"Users: {}\\nMovies: {}\\nRatings: {}\".format(len(users), len(movies), len(ratings)))\n",
    "    \n",
    "    # Pick random state so we will get same samples everytime \n",
    "    np.random.seed(15)\n",
    "    # Pick samples without replacement\n",
    "    sample_users = np.random.choice(users, no_users, replace=False)\n",
    "    sample_movies = np.random.choice(movies, no_movies, replace=False)\n",
    "    \n",
    "    # Get the boolean mask of these sampled indexes from original matrix. \n",
    "    # This will help us to directly use index reference to pick the rating \n",
    "    boolean_mask = np.logical_and(np.isin(row_index, sample_users), np.isin(col_index, sample_movies))\n",
    "    \n",
    "    # Pick the sample values which from the index where boolean_mask is returning true\n",
    "    sample_sparse_matrix = sparse.csc_matrix( (ratings[boolean_mask], (row_index[boolean_mask], col_index[boolean_mask])),\n",
    "                                            shape = (max(sample_users)+1, max(sample_movies)+1) )\n",
    "\n",
    "    print(\"\\nSampled matrix stats\")\n",
    "    print(\"Users: {}\\nMovies: {}\\nRatings: {}\".format(len(sample_users), len(sample_movies), ratings[boolean_mask].shape[0]))\n",
    "    \n",
    "    print('Saving to {}'.format(transformed_folder+'/'+file_name))\n",
    "    sparse.save_npz(transformed_folder+'/'+file_name, sample_sparse_matrix)\n",
    "    return sample_sparse_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c8fb0a",
   "metadata": {},
   "source": [
    "#### 1.1 Create sample_train_sparse_matrix from train_sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c0562ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse matrix for sample train already exists. Getting it from disk...\n",
      "Done!\n",
      "Time taken: 0:00:00.217653\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "if os.path.isfile(transformed_folder+'/sample_train_sparse_matrix.npz'):\n",
    "    print('Sparse matrix for sample train already exists. Getting it from disk...')\n",
    "    sample_train_sparse_matrix = sparse.load_npz(transformed_folder+'/sample_train_sparse_matrix.npz')\n",
    "    print('Done!')\n",
    "    print('Time taken: {}'.format(datetime.now() - start))\n",
    "else:\n",
    "    print('Creating sample_train_sparse_matrix from train_sparse_matrix...')\n",
    "    sample_train_sparse_matrix = get_sample(sparse_matrix=train_sparse_matrix, no_users=25000, \n",
    "                                            no_movies=3000, file_name=\"sample_train_sparse_matrix.npz\")\n",
    "    print('Done!')\n",
    "    print('Time taken: {}'.format(datetime.now() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0971af93",
   "metadata": {},
   "source": [
    "#### 1.2 Create sample_test_sparse_matrix from test_sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b5af4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse matrix for sample test already exists. Getting it from disk...\n",
      "Done!\n",
      "Time taken: 0:00:00.022558\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "if os.path.isfile(transformed_folder+'/sample_test_sparse_matrix.npz'):\n",
    "    print('Sparse matrix for sample test already exists. Getting it from disk...')\n",
    "    sample_test_sparse_matrix = sparse.load_npz(transformed_folder+'/sample_test_sparse_matrix.npz')\n",
    "    print('Done!')\n",
    "    print('Time taken: {}'.format(datetime.now() - start))\n",
    "else:\n",
    "    print('Creating sample_train_sparse_matrix from test_sparse_matrix...')\n",
    "    sample_test_sparse_matrix = get_sample(sparse_matrix=test_sparse_matrix, no_users=15000, \n",
    "                                            no_movies=2000, file_name=\"sample_test_sparse_matrix.npz\")\n",
    "    print('Done!')\n",
    "    print('Time taken: {}'.format(datetime.now() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e058ef97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings in train_sparse_matrix: 80384405\n",
      "Ratings in sample_train_sparse_matrix: 856986\n",
      "\n",
      "Ratings in test_sparse_matrix: 20096102\n",
      "Ratings in sample_test_sparse_matrix: 103997\n"
     ]
    }
   ],
   "source": [
    "# Compare samples with original\n",
    "print('Ratings in train_sparse_matrix: {}'.format(train_sparse_matrix.count_nonzero()))\n",
    "print('Ratings in sample_train_sparse_matrix: {}'.format(sample_train_sparse_matrix.count_nonzero()))\n",
    "\n",
    "print('\\nRatings in test_sparse_matrix: {}'.format(test_sparse_matrix.count_nonzero()))\n",
    "print('Ratings in sample_test_sparse_matrix: {}'.format(sample_test_sparse_matrix.count_nonzero()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99fbb16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change variable names for ease\n",
    "del train_sparse_matrix\n",
    "del test_sparse_matrix\n",
    "train_sparse_matrix = sample_train_sparse_matrix\n",
    "test_sparse_matrix = sample_test_sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d6e2e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings in train_sparse_matrix: 856986\n",
      "Ratings in sample_train_sparse_matrix: 856986\n",
      "\n",
      "Ratings in test_sparse_matrix: 103997\n",
      "Ratings in sample_test_sparse_matrix: 103997\n"
     ]
    }
   ],
   "source": [
    "# After changing variable names\n",
    "print('Ratings in train_sparse_matrix: {}'.format(train_sparse_matrix.count_nonzero()))\n",
    "print('Ratings in sample_train_sparse_matrix: {}'.format(sample_train_sparse_matrix.count_nonzero()))\n",
    "\n",
    "print('\\nRatings in test_sparse_matrix: {}'.format(test_sparse_matrix.count_nonzero()))\n",
    "print('Ratings in sample_test_sparse_matrix: {}'.format(sample_test_sparse_matrix.count_nonzero()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9857f49f",
   "metadata": {},
   "source": [
    "### 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aed592d",
   "metadata": {},
   "source": [
    "#### 2.1 Basic features based on statistics\n",
    "Lets try to build some features that will be useful in modelling. Few such features could be:\n",
    "1. Average of all ratings given\n",
    "2. Average rating per user\n",
    "3. Average rating per movie\n",
    "\n",
    "We will create a dictionary train_averages which will store all these values. Like:<br>\n",
    "train_averages = <br>\n",
    "{<br>\n",
    "'global_average' : xyz,<br>\n",
    "'user' : { 'user1': abc, 'user2':pqr},<br>\n",
    "'movie' : { 'movie1': abc, 'movie2':pqr}<br>\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "406c5151",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_averages = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615241cf",
   "metadata": {},
   "source": [
    "#### Global average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65d8191b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'global_average': 3.5875813607223455}\n",
      "**************************************************\n",
      "Time taken: 0:00:00.020541\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "# Global average\n",
    "train_averages['global_average'] = train_sparse_matrix.sum()/train_sparse_matrix.count_nonzero()\n",
    "print(train_averages)\n",
    "print(\"*\"*50)\n",
    "print('Time taken: {}'.format(datetime.now() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5befab76",
   "metadata": {},
   "source": [
    "#### Average rating per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ad8c613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing average ratings per user...\n",
      "Done!\n",
      "**************************************************\n",
      "Time taken: 0:00:00.494665\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "# Average rating per user\n",
    "print('Computing average ratings per user...')\n",
    "sum_of_ratings_per_user = train_sparse_matrix.sum(axis=1).A1\n",
    "no_of_ratings_per_user = (train_sparse_matrix!=0).sum(axis=1).A1\n",
    "\n",
    "u,m = train_sparse_matrix.shape\n",
    "average_ratings = dict()\n",
    "for i in range(0,u):\n",
    "    if no_of_ratings_per_user[i]!=0:\n",
    "        average_ratings[i] = sum_of_ratings_per_user[i]/no_of_ratings_per_user[i]\n",
    "\n",
    "train_averages['user'] = average_ratings\n",
    "print('Done!')\n",
    "print(\"*\"*50)\n",
    "print('Time taken: {}'.format(datetime.now() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41205b58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average rating given by user 14531 is: 3.7142857142857144\n"
     ]
    }
   ],
   "source": [
    "print('Average rating given by user 14531 is: {}'.format(train_averages['user'][14531]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b916df7",
   "metadata": {},
   "source": [
    "#### Average rating per movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ef4a3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing average ratings per movie...\n",
      "Done!\n",
      "**************************************************\n",
      "Time taken: 0:00:00.014997\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "# Average rating per user\n",
    "print('Computing average ratings per movie...')\n",
    "sum_of_ratings_per_movie = train_sparse_matrix.sum(axis=0).A1\n",
    "no_of_ratings_per_movie = (train_sparse_matrix!=0).sum(axis=0).A1\n",
    "\n",
    "u,m = train_sparse_matrix.shape\n",
    "average_ratings = dict()\n",
    "for i in range(0,m):\n",
    "    if no_of_ratings_per_movie[i]!=0:\n",
    "        average_ratings[i] = sum_of_ratings_per_movie[i]/no_of_ratings_per_movie[i]\n",
    "\n",
    "train_averages['movie'] = average_ratings\n",
    "print('Done!')\n",
    "print(\"*\"*50)\n",
    "print('Time taken: {}'.format(datetime.now() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22ee58a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average rating given for movie 40 is: 2.6923076923076925\n"
     ]
    }
   ],
   "source": [
    "print('Average rating given for movie 40 is: {}'.format(train_averages['movie'][40]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c7697d",
   "metadata": {},
   "source": [
    "#### 2.2 Compute user-user similarity matrix\n",
    "\n",
    "We know that there are more than 400k users. If we try to compute similarity using cosine similarity, we will need to do (400k * 400k / 2) = 80 billions computations, which will take days to compute even though it will only perform on nonzeros. <br>\n",
    "If we try to reduce number of dimensions using PCA or SVD, it will take even more time as the matrix will become dense and the multiplication will be done for each feature as there will not be zero cells. <br><br>\n",
    "\n",
    "One of the ideas is to compute similarity at <b>run time</b>. Here, we will follow below startegy to compute user-user similarity:<br>\n",
    "1. We will compute similarity (top N) for given user (run time)\n",
    "2. Once we compute similarity for any user, we will store this data in our customized data structure so that we can retirve it whenever we want in future\n",
    "3. Now next time if we want to compute similarity for any user, first we will check if we have already computed for that particular user. If yes, then get it from out customized data structure. If not, compute the similarity and store it in our customized data structure.\n",
    "<br><br>\n",
    "Our customized data structure will be a <b>dictionary of dictionaries</b><br>\n",
    "{ 'user1': {'similar_user1' : value1 }, {'similar_user2' : value2 }, {'similar_user3' : value3 } <br>\n",
    "  'user2': {'similar_user1' : value1 }, {'similar_user2' : value2 }, {'similar_user3' : value3 } }\n",
    "  \n",
    "<br>\n",
    "For now, since we have taken sample of users, lets compute similarity using cosine_similarity which wouldn't take much time.<br>\n",
    "<b>From the result of this, we will pick top 5 similar users and take them as features to train our model.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a042bd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4d187ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse matrix for user-user similarity already exists, getting it from disk... \n",
      "Done!\n",
      "Time taken; 0:00:31.186462\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "# To compute this, we will use consine similarity\n",
    "if os.path.isfile(transformed_folder+'/u_u_similarity_sparse.npz'):\n",
    "    print('Sparse matrix for user-user similarity already exists, getting it from disk... ')\n",
    "    u_u_similarity_sparse = sparse.load_npz(transformed_folder+'/u_u_similarity_sparse.npz')\n",
    "    print('Done!')\n",
    "    print('Time taken; {}'.format(datetime.now() - start))\n",
    "else:\n",
    "    print('Creating sparse matrix for user-user similarity...')\n",
    "    u_u_similarity_sparse = cosine_similarity(X=train_sparse_matrix, dense_output=Falseb)\n",
    "    print('Saving to {}'.format(transformed_folder+'/u_u_similarity_sparse.npz'))\n",
    "    sparse.save_npz(transformed_folder+'/u_u_similarity_sparse.npz', u_u_similarity_sparse)\n",
    "    print('Done!')\n",
    "    print('Time taken: {}'.format(datetime.now() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4162b891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of user-user similarity matrix: (2649405, 2649405)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of user-user similarity matrix: {}'.format(u_u_similarity_sparse.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a529862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique user IDs\n",
    "user_ids = np.unique(u_u_similarity_sparse.nonzero()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb2cb9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique users: 24029\n"
     ]
    }
   ],
   "source": [
    "print('Total number of unique users: {}'.format(len(user_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc75eee4",
   "metadata": {},
   "source": [
    "#### 2.3 Compute movie-movie similarity matrix\n",
    "\n",
    "We know that there are around 17k movies in total. If we try to compute cosine similarity, we will need to do (17k * 17k / 2) = 144 millions computations, which would not take much longer. In this case, we can definately go with cosine similarity to get similar movies for each movie.\n",
    "\n",
    "<br>\n",
    "<b>From the result of this, we will pick top 5 similar movies and take them as features to train our model.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30cd42c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating sparse matrix for movie-movie similarity...\n",
      "Saving to F:/09 - Machine Learning Case Studies/01 - Netflix Movies Recommendation/Transformed Data/m_m_similarity_sparse.npz\n",
      "Done!\n",
      "Time taken: 0:00:04.083615\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "# To compute this, we will use consine similarity\n",
    "if os.path.isfile(transformed_folder+'/m_m_similarity_sparse.npz'):\n",
    "    print('Sparse matrix for movie-movie similarity already exists, getting it from disk... ')\n",
    "    m_m_similarity_sparse = sparse.load_npz(transformed_folder+'/m_m_similarity_sparse.npz')\n",
    "    print('Done!')\n",
    "    print('Time taken; {}'.format(datetime.now() - start))\n",
    "else:\n",
    "    print('Creating sparse matrix for movie-movie similarity...')\n",
    "    m_m_similarity_sparse = cosine_similarity(X=train_sparse_matrix.T, dense_output=False)\n",
    "    print('Saving to {}'.format(transformed_folder+'/m_m_similarity_sparse.npz'))\n",
    "    sparse.save_npz(transformed_folder+'/m_m_similarity_sparse.npz', m_m_similarity_sparse)\n",
    "    print('Done!')\n",
    "    print('Time taken: {}'.format(datetime.now() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d297655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of movie-movie similarity matrix: (17755, 17755)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of movie-movie similarity matrix: {}'.format(m_m_similarity_sparse.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "beae34db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique movie IDs which have atleast 1 rating\n",
    "movie_ids = np.unique(m_m_similarity_sparse.nonzero()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90fafa98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique movies: 2958\n"
     ]
    }
   ],
   "source": [
    "print('Total number of unique movies: {}'.format(len(movie_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8d2a80",
   "metadata": {},
   "source": [
    "### 3. Featurizing/Preparing Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726d16f0",
   "metadata": {},
   "source": [
    "As of now, we have decided to have features to train our model on:\n",
    "1. Global average\n",
    "2. Average rating by the user\n",
    "3. Average rating for the movie\n",
    "4. Ratings received from top 5 similar users for the movie\n",
    "5. Ratings given for top 5 similar movies from the user\n",
    "\n",
    "In total, we have 13 features to train our base model on. Lets featurize these to bring them in a required format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d4783d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of ratings in train matrix is : 856986\n",
      "No of ratings in test matrix is  : 103997\n"
     ]
    }
   ],
   "source": [
    "print('No of ratings in train matrix is : {}'.format(train_sparse_matrix.count_nonzero()))\n",
    "print('No of ratings in test matrix is  : {}'.format(test_sparse_matrix.count_nonzero()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bead6f0e",
   "metadata": {},
   "source": [
    "#### 3.1 Featurize/prepare train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40b602f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation complete!\n"
     ]
    }
   ],
   "source": [
    "# get users, movies and ratings from our train sparse matrix\n",
    "train_users, train_movies, train_ratings = sparse.find(train_sparse_matrix)\n",
    "print('Operation complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "89eb082b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurized train already exists.\n",
      "Time taken: {} 0:00:00.001003\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "model_data_folder = 'C:/Users/ParikshitShinge/Downloads/09 - Machine Learning Case Studies/01 - Netflix Movies Recommendation/Model Ready Data'\n",
    "if os.path.isfile(model_data_folder+'/featurized_train.csv'):\n",
    "    print('Featurized train already exists.')\n",
    "else:\n",
    "    print('Preparing featurized_train.csv file for {} ratings...'.format(train_ratings))\n",
    "    \n",
    "    with open(model_data_folder+'/featurized_train.csv', mode='w') as featurized_train_file:\n",
    "        user_counter = 0\n",
    "        \n",
    "        # Loop for each user-movie-rating combination\n",
    "        for (user, movie, rating) in zip(train_users, train_movies, train_ratings):\n",
    "            \n",
    "            # Lets get rating for the \"movie\" by similar users\n",
    "            top_sim_users = u_u_similarity_sparse[user].toarray().ravel().argsort()[::-1][1:]\n",
    "            top_ratings = train_sparse_matrix[top_sim_users, movie].toarray().ravel()\n",
    "            top_sim_users_ratings = list(top_ratings[top_ratings != 0][:5])\n",
    "            top_sim_users_ratings.extend([train_averages['movie'][movie]] * (5 - len(top_sim_users_ratings))) # Fill up the zeros with movie's average rating by all users\n",
    "            \n",
    "            # Lets get rating by the \"user\" for similar movies\n",
    "            top_sim_movies = m_m_similarity_sparse[movie].toaray().ravel().argsort()[::-1][1:]\n",
    "            top_ratings = train_sparse_matrix[user, top_sim_movies].toarray().ravel()\n",
    "            top_sim_movies_ratings = list(top_ratings[top_ratings !=0][:5])\n",
    "            top_sim_movies_ratings.extend([train_averages['user'][user]] * (5 - len(top_sim_movies_ratings))) # Fill up the zeros with user's average rating for all movies\n",
    "            \n",
    "            # Prepare a row to insert into featurized file\n",
    "            row = list()\n",
    "            row.append(user)\n",
    "            row.append(movie)\n",
    "            row.append(rating)\n",
    "            row.append(train_averages['global'])\n",
    "            row.append(train_averages['user'][user])\n",
    "            row.append(train_averages['movie'][movie])\n",
    "            row.extend(top_sim_users_ratings)\n",
    "            row.extend(top_sim_movies_ratings)\n",
    "            \n",
    "            # Increase the count for verbose\n",
    "            user_counter = user_counter + 1\n",
    "            \n",
    "            # Add the row to file\n",
    "            featurized_train_file.write(','.join(map(str, row)))\n",
    "            featurized_train_file.write('\\n')\n",
    "            if user_counter%1000 == 0:\n",
    "                print('Done for {} rows in {}'.format(user_counter, datetime.now()-start ))\n",
    "            \n",
    "print('Time taken: {}', datetime.now()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5168b077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>movie</th>\n",
       "      <th>GAvg</th>\n",
       "      <th>sur1</th>\n",
       "      <th>sur2</th>\n",
       "      <th>sur3</th>\n",
       "      <th>sur4</th>\n",
       "      <th>sur5</th>\n",
       "      <th>smr1</th>\n",
       "      <th>smr2</th>\n",
       "      <th>smr3</th>\n",
       "      <th>smr4</th>\n",
       "      <th>smr5</th>\n",
       "      <th>UAvg</th>\n",
       "      <th>MAvg</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53406</td>\n",
       "      <td>33</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.370370</td>\n",
       "      <td>4.092437</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99540</td>\n",
       "      <td>33</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.555556</td>\n",
       "      <td>4.092437</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99865</td>\n",
       "      <td>33</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>4.092437</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101620</td>\n",
       "      <td>33</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.584416</td>\n",
       "      <td>4.092437</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>112974</td>\n",
       "      <td>33</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>4.092437</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user  movie      GAvg  sur1  sur2  sur3  sur4  sur5  smr1  smr2  smr3  \\\n",
       "0   53406     33  3.581679   4.0   5.0   5.0   4.0   1.0   5.0   2.0   5.0   \n",
       "1   99540     33  3.581679   5.0   5.0   5.0   4.0   5.0   3.0   4.0   4.0   \n",
       "2   99865     33  3.581679   5.0   5.0   4.0   5.0   3.0   5.0   4.0   4.0   \n",
       "3  101620     33  3.581679   2.0   3.0   5.0   5.0   4.0   4.0   3.0   3.0   \n",
       "4  112974     33  3.581679   5.0   5.0   5.0   5.0   5.0   3.0   5.0   5.0   \n",
       "\n",
       "   smr4  smr5      UAvg      MAvg  rating  \n",
       "0   3.0   1.0  3.370370  4.092437       4  \n",
       "1   3.0   5.0  3.555556  4.092437       3  \n",
       "2   5.0   4.0  3.714286  4.092437       5  \n",
       "3   4.0   5.0  3.584416  4.092437       5  \n",
       "4   5.0   3.0  3.750000  4.092437       5  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featurized_train = pd.read_csv(model_data_folder+'/featurized_train.csv', names = ['user', 'movie', 'GAvg', 'sur1', 'sur2', 'sur3', 'sur4', 'sur5','smr1', 'smr2', 'smr3', 'smr4', 'smr5', 'UAvg', 'MAvg', 'rating'], header=None)\n",
    "featurized_train.head()\n",
    "\n",
    "# GAvg : Average rating of all the ratings \n",
    "# Similar users rating of this movie : sur1, sur2, sur3, sur4, sur5 ( top 5 similar users who rated that movie.. )\n",
    "# Similar movies rated by this user : smr1, smr2, smr3, smr4, smr5 ( top 5 similar movies rated by this movie.. )\n",
    "# UAvg : User's Average rating\n",
    "# MAvg : Average rating of this movie\n",
    "# rating : Rating of this movie by this user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018a8833",
   "metadata": {},
   "source": [
    "#### 3.2 Featurize/prepare test data\n",
    "\n",
    "Here, we will face cold start problem for the users & movies which are not present in train dataset. We will try to catch these exceptions using error handling and assign them global averages to all the features since we do not have any historical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d65cbd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation complete!\n"
     ]
    }
   ],
   "source": [
    "# get users, movies and ratings from our train sparse matrix\n",
    "test_users, test_movies, test_ratings = sparse.find(test_sparse_matrix)\n",
    "print('Operation complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a252b9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurized test already exists.\n",
      "Time taken: {} 0:00:00\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "if os.path.isfile(model_data_folder+'/featurized_test.csv'):\n",
    "    print('Featurized test already exists.')\n",
    "else:\n",
    "    print('Preparing featurized_test.csv file for {} ratings...'.format(test_ratings))\n",
    "    \n",
    "    with open(model_data_folder+'/featurized_test.csv', mode='w') as featurized_test_file:\n",
    "        user_counter = 0\n",
    "        \n",
    "        # Loop for each user-movie-rating combination\n",
    "        for (user, movie, rating) in zip(test_users, test_movies, test_ratings):\n",
    "            \n",
    "            try:\n",
    "                # Lets get rating for the \"movie\" by similar users\n",
    "                top_sim_users = u_u_similarity_sparse[user].toarray().ravel().argsort()[::-1][1:]\n",
    "                top_ratings = train_sparse_matrix[top_sim_users, movie].toarray().ravel()\n",
    "                top_sim_users_ratings = list(top_ratings[top_ratings != 0][:5])\n",
    "                top_sim_users_ratings.extend([train_averages['movie'][movie]] * (5 - len(top_sim_users_ratings))) # Fill up the zeros with movie's average rating by all users\n",
    "            except (IndexError, KeyError):\n",
    "                # COLD START PROBLEM\n",
    "                top_sim_users_ratings.extend([train_averages['global']] * (5 - len(top_sim_users_ratings)))\n",
    "            except:\n",
    "                print('Exception for {} user and {} movie'.format(user, movie))\n",
    "                raise\n",
    "\n",
    "            try:\n",
    "                # Lets get rating by the \"user\" for similar movies\n",
    "                top_sim_movies = m_m_similarity_sparse[movie].toaray().ravel().argsort()[::-1][1:]\n",
    "                top_ratings = train_sparse_matrix[user, top_sim_movies].toarray().ravel()\n",
    "                top_sim_movies_ratings = list(top_ratings[top_ratings !=0][:5])\n",
    "                top_sim_movies_ratings.extend([train_averages['user'][user]] * (5 - len(top_sim_movies_ratings))) # Fill up the zeros with user's average rating for all movies\n",
    "            except (IndexError, KeyError):\n",
    "                # COLD START PROBLEM\n",
    "                top_sim_users_ratings.extend([train_averages['global']] * (5 - len(top_sim_users_ratings)))\n",
    "            except:\n",
    "                print('Exception for {} user and {} movie'.format(user, movie))\n",
    "                raise                \n",
    "                \n",
    "            # Prepare a row to insert into featurized file\n",
    "            row = list()\n",
    "            row.append(user)\n",
    "            row.append(movie)\n",
    "            row.append(rating)\n",
    "            row.append(train_averages['global'])\n",
    "            try:\n",
    "                row.append(train_averages['user'][user])\n",
    "            except KeyError:\n",
    "                row.append(train_averages['global'])\n",
    "            try:\n",
    "                row.append(train_averages['movie'][movie])\n",
    "            except KeyError:\n",
    "                row.append(train_averages['global'])\n",
    "                \n",
    "            row.extend(top_sim_users_ratings)\n",
    "            row.extend(top_sim_movies_ratings)\n",
    "            \n",
    "            # Increase the count for verbose\n",
    "            user_counter = user_counter + 1\n",
    "            \n",
    "            # Add the row to file\n",
    "            featurized_test_file.write(','.join(map(str, row)))\n",
    "            featurized_test_file.write('\\n')\n",
    "            if user_counter%1000 == 0:\n",
    "                print('Done for {} rows in {}'.format(user_counter, datetime.now()-start ))\n",
    "            \n",
    "print('Time taken: {}', datetime.now()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b1a4e030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>movie</th>\n",
       "      <th>GAvg</th>\n",
       "      <th>sur1</th>\n",
       "      <th>sur2</th>\n",
       "      <th>sur3</th>\n",
       "      <th>sur4</th>\n",
       "      <th>sur5</th>\n",
       "      <th>smr1</th>\n",
       "      <th>smr2</th>\n",
       "      <th>smr3</th>\n",
       "      <th>smr4</th>\n",
       "      <th>smr5</th>\n",
       "      <th>UAvg</th>\n",
       "      <th>MAvg</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>808635</td>\n",
       "      <td>71</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>941866</td>\n",
       "      <td>71</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1737912</td>\n",
       "      <td>71</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1849204</td>\n",
       "      <td>71</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28572</td>\n",
       "      <td>111</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user  movie      GAvg      sur1      sur2      sur3      sur4      sur5  \\\n",
       "0   808635     71  3.581679  3.581679  3.581679  3.581679  3.581679  3.581679   \n",
       "1   941866     71  3.581679  3.581679  3.581679  3.581679  3.581679  3.581679   \n",
       "2  1737912     71  3.581679  3.581679  3.581679  3.581679  3.581679  3.581679   \n",
       "3  1849204     71  3.581679  3.581679  3.581679  3.581679  3.581679  3.581679   \n",
       "4    28572    111  3.581679  3.581679  3.581679  3.581679  3.581679  3.581679   \n",
       "\n",
       "       smr1      smr2      smr3      smr4      smr5      UAvg      MAvg  \\\n",
       "0  3.581679  3.581679  3.581679  3.581679  3.581679  3.581679  3.581679   \n",
       "1  3.581679  3.581679  3.581679  3.581679  3.581679  3.581679  3.581679   \n",
       "2  3.581679  3.581679  3.581679  3.581679  3.581679  3.581679  3.581679   \n",
       "3  3.581679  3.581679  3.581679  3.581679  3.581679  3.581679  3.581679   \n",
       "4  3.581679  3.581679  3.581679  3.581679  3.581679  3.581679  3.581679   \n",
       "\n",
       "   rating  \n",
       "0       5  \n",
       "1       4  \n",
       "2       3  \n",
       "3       4  \n",
       "4       1  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featurized_test = pd.read_csv(model_data_folder+'/featurized_test.csv', names = ['user', 'movie', 'GAvg', 'sur1', 'sur2', 'sur3', 'sur4', 'sur5','smr1', 'smr2', 'smr3', 'smr4', 'smr5','UAvg', 'MAvg', 'rating'], header=None)\n",
    "featurized_test.head()\n",
    "\n",
    "\n",
    "# GAvg : Average rating of all the ratings \n",
    "# Similar users rating of this movie : sur1, sur2, sur3, sur4, sur5 ( top 5 similar users who rated that movie.. )\n",
    "# Similar movies rated by this user : smr1, smr2, smr3, smr4, smr5 ( top 5 similar movies rated by this movie.. )\n",
    "# UAvg : User's Average rating\n",
    "# MAvg : Average rating of this movie\n",
    "# rating : Rating of this movie by this user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d029ec09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ds] *",
   "language": "python",
   "name": "conda-env-ds-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
